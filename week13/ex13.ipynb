{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc5acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e45043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.load(\"casper/calib.npy\", allow_pickle=True).item()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4b43b",
   "metadata": {},
   "source": [
    "## Ex 13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "im0 = cv2.imread(\"casper/sequence/frames0_0.png\")\n",
    "im0 = cv2.cvtColor(im0, cv2.COLOR_BGR2GRAY)\n",
    "im0 = im0.astype(float) / 255\n",
    "size = (im0.shape[1], im0.shape[0])\n",
    "stereo = cv2.stereoRectify(\n",
    "    c[\"K0\"], c[\"d0\"], c[\"K1\"], c[\"d1\"], size, c[\"R\"], c[\"t\"], flags=0\n",
    ")\n",
    "R0, R1, P0, P1 = stereo[:4]\n",
    "maps0 = cv2.initUndistortRectifyMap(c[\"K0\"], c[\"d0\"], R0, P0, size, cv2.CV_32FC2)\n",
    "maps1 = cv2.initUndistortRectifyMap(c[\"K1\"], c[\"d1\"], R1, P1, size, cv2.CV_32FC2)\n",
    "# im0 should come from maps0\n",
    "im0_rect = cv2.remap(im0, *maps0, cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im0, cmap=\"gray\")\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(im0_rect, cmap=\"gray\")\n",
    "axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dedb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rectify all images\n",
    "n_frames = 26\n",
    "cam_0_ims1  = np.zeros((n_frames, size[1], size[0]))\n",
    "cam_1_ims1  = np.zeros((n_frames, size[1], size[0]))\n",
    "for i in range(n_frames):\n",
    "    # Load and convert to grayscale\n",
    "    img0 = (\n",
    "        cv2.imread(\"casper/\" +\"sequence/frames0_%d.png\" % i)\n",
    "        .astype(float)\n",
    "        .mean(2)\n",
    "        / 255\n",
    "    )\n",
    "    img1 = (\n",
    "        cv2.imread(\"casper/\" + \"sequence/frames1_%d.png\" % i).astype(float).mean(2)\n",
    "        / 255\n",
    "    )\n",
    "    cam_0_ims1 [i] = cv2.remap(img0, *maps0, cv2.INTER_LINEAR)\n",
    "    cam_1_ims1 [i] = cv2.remap(img1, *maps1, cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b754c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_number(filename):\n",
    "    match = re.search(r\"_(\\d+)\\.png$\", filename)\n",
    "    return int(match.group(1)) if match else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = \"casper/sequence/\"\n",
    "# # List is named such that cam_<number>_im_<fully on - 0 fully off - 1>\n",
    "# cam_0_ims0 = []\n",
    "# cam_0_ims1 = []\n",
    "# for name in sorted(glob.glob(folder_path + \"frames0*.png\"), key=extract_number):\n",
    "#     print(name)\n",
    "#     image = cv2.imread(name).astype(float).mean(2) / 255\n",
    "#     image_rect = cv2.remap(image, *maps0, cv2.INTER_LINEAR)\n",
    "#     cam_0_ims0.append(image)\n",
    "#     cam_0_ims1.append(image_rect)\n",
    "# len(cam_0_ims0), len(cam_0_ims1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4af0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = \"casper/sequence/\"\n",
    "# cam_1_ims0 = []\n",
    "# cam_1_ims1 = []\n",
    "# for name in sorted(glob.glob(folder_path + \"frames1*.png\"), key=extract_number):\n",
    "#     print(name)\n",
    "#     image = cv2.imread(name).astype(float).mean(2) / 255\n",
    "#     image_rect = cv2.remap(image, *maps0, cv2.INTER_LINEAR)\n",
    "#     cam_1_ims0.append(image)\n",
    "#     cam_1_ims1.append(image_rect)\n",
    "# len(cam_1_ims0), len(cam_1_ims1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4547450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 2)\n",
    "# axes[0].imshow(cam_0_ims0[0], cmap=\"gray\")\n",
    "# axes[0].axis(\"off\")\n",
    "# axes[1].imshow(cam_0_ims1[0], cmap=\"gray\")\n",
    "# axes[1].axis(\"off\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f38a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 2)\n",
    "# axes[0].imshow(cam_1_ims0[0], cmap=\"gray\")\n",
    "# axes[0].axis(\"off\")\n",
    "# axes[1].imshow(cam_1_ims1[0], cmap=\"gray\")\n",
    "# axes[1].axis(\"off\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1413e005",
   "metadata": {},
   "source": [
    "## Ex 13.3\n",
    "At this point, we are ready to make a function that can compute the phases for each camera theta\n",
    "= unwrap(ims). I suggest to write the code for camera 0 and to put it into a function once it’s working.\n",
    "* Use indexing to get a list of the primary images out, and make sure it has length 16. \n",
    "* Put this list into the Fast Fourier Transform (np.fft.rfft) to find the Fourier spectrums of the primary images (fft_primary). We use rfft as the input is only real numbers. The function can operate on a list of arrays, which is ideal for our situation. Make sure to specify that the FFT should\n",
    "operate along the first dimension of the array (axis=0). The Fourier component corresponding to the pattern is in the second component (fft_primary[1]).\n",
    "* Get the phase of this using np.angle and call it theta_primary.\n",
    "* Repeat the same steps for the secondary phase to obtain theta_secondary. * Compute the phase cue (theta_c) using the heterodyne principle.\n",
    "* Find the order (o_primary) of the primary phase.\n",
    "Use the order of the primary phase to obtain the unwrapped phase (theta).\n",
    "Wrap all of the above into a function theta = unwrap(ims) and use it to obtain the phase for both cameras (theta0 and theta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd20c8d",
   "metadata": {},
   "source": [
    "2-17 are the 16 images in the primary pattern shifting. This pattern has 40 periods.\n",
    "18-25 are the 8 images of the secondary pattern shifting. This pattern has 41 periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam0_primary = cam_0_ims1[2: 18]\n",
    "cam0_secondary = cam_0_ims1[18: 26]\n",
    "cam1_primary = cam_1_ims1[2: 18]\n",
    "cam1_secondary = cam_1_ims1[18: 26]\n",
    "len(cam0_primary), len(cam1_primary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c2450",
   "metadata": {},
   "source": [
    "![unwrapping](images/unwrapping.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15eaa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_primary = np.fft.rfft(cam0_primary, axis=0)\n",
    "theta_primary = np.angle(fft_primary[1])\n",
    "fft_secondary = np.fft.rfft(cam0_secondary, axis=0)\n",
    "theta_secondary = np.angle(fft_secondary[1])\n",
    "theta_c = (theta_secondary - theta_primary) % (2 * np.pi)\n",
    "n_primary = 40\n",
    "o_primary = (n_primary * theta_c - theta_primary) / (2 * np.pi)\n",
    "theta_est = ((2 * np.pi * o_primary + theta_primary) / n_primary) % (2 * np.pi)\n",
    "plt.imshow(theta_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0188d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _unwrap(ims: np.array):\n",
    "    \"\"\"\n",
    "        Given a list of images with indexes, \n",
    "        do an unwrap on phase-shift encoded images using phase cue and heterodyne principal for more robust estimation.\n",
    "        2-17 are the 16 images in the primary pattern shifting. This pattern has 40 periods.\n",
    "        18-25 are the 8 images of the secondary pattern shifting. This pattern has 41 periods.\n",
    "        Args:\n",
    "            ims (np.array): list of images\n",
    "        Return:\n",
    "            theta_est (np.array): estimate absolute phase value, which corresponds to a specific position in the projected pattern and thus the depth of the object.\n",
    "    \"\"\"\n",
    "    cam_primary = ims[2: 18]\n",
    "    cam_secondary = ims[18: 26]\n",
    "    fft_primary = np.fft.rfft(cam_primary, axis=0)\n",
    "    theta_primary = np.angle(fft_primary[1])\n",
    "    fft_secondary = np.fft.rfft(cam_secondary, axis=0)\n",
    "    theta_secondary = np.angle(fft_secondary[1])\n",
    "    theta_c = (theta_secondary - theta_primary) % (2 * np.pi)\n",
    "    n_primary = 40\n",
    "    o_primary = (n_primary * theta_c - theta_primary) / (2 * np.pi)\n",
    "    theta_est = ((2 * np.pi * o_primary + theta_primary) / n_primary) % (2 * np.pi)\n",
    "    return theta_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89effbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 13.3\n",
    "def unwrap(imgs, n1):\n",
    "    \"\"\"\n",
    "    Unwrap the measured phases. Adapter from Collister.\n",
    "\n",
    "    Args:\n",
    "        imgs (List[np.ndarray]): List of images from the cameras.\n",
    "        n1 (int): Period of the primary pattern.\n",
    "\n",
    "    Returns:\n",
    "        theta_est (np.ndarray) : The phase of the primary pattern.\n",
    "    \"\"\"\n",
    "    # Primary pattern\n",
    "    primary_images = imgs[2:18]  # 16 images\n",
    "    fft_primary = np.fft.rfft(primary_images, axis=0)\n",
    "    fourier_primary = fft_primary[1]\n",
    "    theta_primary = np.angle(fourier_primary)\n",
    "\n",
    "    # Secondary pattern\n",
    "    secondary_images = imgs[18:26]\n",
    "    fft_secondary = np.fft.rfft(secondary_images, axis=0)\n",
    "    fourier_secondary = fft_secondary[1]\n",
    "    theta_secondary = np.angle(fourier_secondary)\n",
    "\n",
    "    # Compute phase cue using heterodyne principle\n",
    "    theta_c = np.mod(theta_secondary - theta_primary, 2 * np.pi)\n",
    "\n",
    "    # Order of primary phase\n",
    "    o_primary = np.rint((n1 * theta_c - theta_primary) / (2 * np.pi))\n",
    "\n",
    "    # Estimate the phase\n",
    "    theta_est = np.mod((2 * np.pi * o_primary + theta_primary) / n1, 2 * np.pi)\n",
    "    return theta_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a50ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_est0 = unwrap(cam_0_ims1, 40)\n",
    "plt.imshow(theta_est0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_est1 = unwrap(cam_1_ims1, 40)\n",
    "plt.imshow(theta_est1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d0b00c",
   "metadata": {},
   "source": [
    "## Ex 13.4\n",
    "When inspecting the phase images theta0 and theta1 it is clear that not all pixels contain a valid measurement of the phase. This is because some pixels do not reflect enough light from the\n",
    "projector to give a meaningful measurement. To fix this we introduce a binary mask that contains\n",
    "3\n",
    "the areas that are sufficiently illuminated by the projector. Subtract the fully on and fully off\n",
    "projector image from each other (the first two elements of ims), to obtain a measurement of how\n",
    "much projector light is in each pixel.\n",
    "\n",
    "0 is an image fully illuminated by the projector (projector showing a white image)\n",
    "1 is an image with the projector fully off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e5721",
   "metadata": {},
   "source": [
    "### Trying with cam0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce39dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff0 = cam_0_ims1[0] - cam_0_ims1[1]\n",
    "mask0 = (diff0 > (15 / 255)).astype(np.uint8)\n",
    "mask0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e20f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1 = cam_1_ims1[0] - cam_1_ims1[1]\n",
    "mask1 = (diff1 > (15 / 255)).astype(np.uint8)\n",
    "mask1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1864bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(mask0, cmap=\"gray\")\n",
    "axes[1].imshow(mask1, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d802f",
   "metadata": {},
   "source": [
    "## Ex 13.5\n",
    "Now we need to find matches between the two cameras. As the images are rectified, we can constrain ourselves to search for a match on the  corresponding row in the other image.\\\n",
    "That is we need to create two lists (q0s and q1s) that contain the pixel coordinates of matches between camera 0 and 1.\\\n",
    "Use a double for-loop to iterate over all pixels in camera 0. For each valid pixel (mask0[i0,j0] = True which has the phase theta0[i0,j0]), we need to find the pixel in the other image that matches the best. \\\n",
    "As the images are rectified the epipolar line is a the row i0 in camera 1. Thus, we find the matching pixel in camera 1, selecting the pixel from row i0 which is valid mask1[i0,j1] = True and which has the closest phase match: theta0[i0,j0] ∼ theta1[i0,j1].\\\n",
    "Be aware that the points have to be of the form (x, y) i.e. [j, i], in order to work with our projection matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c09b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = mask0.shape\n",
    "shape1 = mask1.shape\n",
    "q0s = []\n",
    "q1s = []\n",
    "disparity = np.zeros_like(mask0, dtype=np.float32)  # Initialize with zeros\n",
    "\n",
    "# Iterate over all pixels in camera 0\n",
    "for i0 in range(shape[0]):\n",
    "    point0 = (0, 0)\n",
    "    point1 = (0, 0)\n",
    "    for j0 in range(shape[1]):\n",
    "        minDiff = 1000000\n",
    "        if mask0[i0, j0]:  # valid pixel\n",
    "            phase = theta_est0[i0][j0]\n",
    "            epipolar_row = theta_est1[i0]  # row i0 in camera 1\n",
    "            valid_epipolar_row = epipolar_row * mask1[i0]\n",
    "\n",
    "            # closest phase match\n",
    "            j1 = (np.abs(valid_epipolar_row - phase)).argmin()\n",
    "            q0s.append([j0, i0])\n",
    "            q1s.append([j1, i0])\n",
    "            disparity[i0][j0] = j0 - j1\n",
    "\n",
    "plt.imshow(cv2.medianBlur(disparity.astype(np.float32), 5))\n",
    "plt.title(\"Disparity map\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(q0s), len(q1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.medianBlur(disparity.astype(np.float32), 5))\n",
    "plt.title(\"Disparity map\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8722f31d",
   "metadata": {},
   "source": [
    "## Ex 13.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b022c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 13.6\n",
    "# Triangulate the 3D points\n",
    "projPoints0 = np.array(q0s).T.astype(np.float32)\n",
    "projPoints1 = np.array(q1s).T.astype(np.float32)\n",
    "\n",
    "Q = cv2.triangulatePoints(\n",
    "    projMatr1=P0, projMatr2=P1, projPoints1=projPoints0, projPoints2=projPoints1\n",
    ")\n",
    "Q = Q[:-1] / Q[-1]  # convert to non-homogenous\n",
    "\n",
    "# # Remove negative z-coordinates that are behind the camera\n",
    "# Q_mask = np.where(Q[2] > 0, True, False)\n",
    "# Q_fixed = (Q.T[Q_mask]).T\n",
    "\n",
    "# # Visualize 3D point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(Q.T)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pc_testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
